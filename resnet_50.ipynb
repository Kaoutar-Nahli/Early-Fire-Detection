{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from google.colab import drive\r\n",
    "drive.mount('\\content\\drive')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\r\n",
    "import torch\r\n",
    "import torch.nn as nn\r\n",
    "from torchvision import datasets, transforms, models\r\n",
    "from numpy import isnan\r\n",
    "import torch.nn.functional as F\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "import sklearn\r\n",
    "from torch.nn import functional as F\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "import pandas as pd\r\n",
    "from datetime import datetime\r\n",
    "from os import path as os_path\r\n",
    "from torch.utils.data import DataLoader\r\n",
    "from sklearn import model_selection\r\n",
    "from sklearn import preprocessing\r\n",
    "from sklearn import preprocessing\r\n",
    "from sklearn.metrics import f1_score\r\n",
    "import torch.optim as optim\r\n",
    "#%%\r\n",
    "transforms_train = transforms.Compose([transforms.Resize(225),\r\n",
    "                                       transforms.CenterCrop(224),\r\n",
    "                                       transforms.ToTensor(),\r\n",
    "                                       transforms.Normalize([0.5, 0.5, 0.5],\r\n",
    "                                                            [0.5, 0.5, 0.5])])\r\n",
    "\r\n",
    "transforms_test = transforms.Compose([transforms.Resize(225),\r\n",
    "                                       transforms.CenterCrop(224),\r\n",
    "                                       transforms.ToTensor(),\r\n",
    "                                       transforms.Normalize([0.5, 0.5, 0.5],\r\n",
    "                                                            [0.5, 0.5, 0.5])])\r\n",
    "#reading data from drive\r\n",
    "train_data = datasets.ImageFolder(root='/content/drive/MyDrive/data/FIRE-SMOKE-DATASET/Train', transform=transforms_train)\r\n",
    "test_data = datasets.ImageFolder(root='/content/drive/MyDrive/data/FIRE-SMOKE-DATASET/Test', transform=transforms_test)\r\n",
    "print(len(train_data), len(test_data))\r\n",
    "\r\n",
    "#%%\r\n",
    "#spliting the data\r\n",
    "train_data, val_data = torch.utils.data.random_split(train_data, [2400,300])\r\n",
    "#%%\r\n",
    "train_data_loader = torch.utils.data.DataLoader(train_data, batch_size=64, shuffle=True)\r\n",
    "val_data_loader = torch.utils.data.DataLoader(val_data, batch_size=64, shuffle=True)\r\n",
    "test_data_loader = torch.utils.data.DataLoader(test_data,  batch_size=64, shuffle=True)\r\n",
    "\r\n",
    "\r\n",
    "#%%\r\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() \r\n",
    "                                  else \"cpu\")\r\n",
    "model = models.resnet50(pretrained=True)\r\n",
    "print(model)\r\n",
    "#%%\r\n",
    "#How to Train an Image Classifier in PyTorch and use it to Perform Basic Inference on Single Images\r\n",
    "for param in model.parameters():\r\n",
    "    param.requires_grad = False\r\n",
    "    \r\n",
    "model.fc = nn.Sequential(nn.Linear(2048, 512),\r\n",
    "                                 nn.ReLU(),\r\n",
    "                                 nn.Dropout(0.2),\r\n",
    "                                 nn.Linear(512, 10),\r\n",
    "                                 nn.LogSoftmax(dim=1))\r\n",
    "criterion = nn.NLLLoss()\r\n",
    "optimizer = optim.Adam(model.fc.parameters(), lr=0.003)\r\n",
    "model.to(device)\r\n",
    "\r\n",
    "#%%\r\n",
    "epochs = 20\r\n",
    "steps = 0\r\n",
    "running_loss = 0\r\n",
    "print_every = 1\r\n",
    "train_losses, test_losses = [], []\r\n",
    "for epoch in range(epochs):\r\n",
    "    for inputs, labels in train_data_loader:\r\n",
    "        steps += 1\r\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\r\n",
    "        optimizer.zero_grad()\r\n",
    "        logps = model.forward(inputs)\r\n",
    "        loss = criterion(logps, labels)\r\n",
    "        loss.backward()\r\n",
    "        optimizer.step()\r\n",
    "        running_loss += loss.item()\r\n",
    "        \r\n",
    "        if steps % print_every == 0:\r\n",
    "            test_loss = 0\r\n",
    "            accuracy = 0\r\n",
    "            model.eval()\r\n",
    "            with torch.no_grad():\r\n",
    "                for inputs, labels in test_data_loader:\r\n",
    "                    inputs, labels = inputs.to(device),labels.to(device)\r\n",
    "                    logps = model.forward(inputs)\r\n",
    "                    batch_loss = criterion(logps, labels)\r\n",
    "                    test_loss += batch_loss.item()\r\n",
    "                    \r\n",
    "                    ps = torch.exp(logps)\r\n",
    "                    top_p, top_class = ps.topk(1, dim=1)\r\n",
    "                    equals = top_class == labels.view(*top_class.shape)\r\n",
    "                    accuracy +=torch.mean(equals.type(torch.FloatTensor)).item()\r\n",
    "            train_losses.append(running_loss/len(train_data_loader))\r\n",
    "            test_losses.append(test_loss/len(test_data_loader))                    \r\n",
    "            print(f\"Epoch {epoch+1}/{epochs}.. \"\r\n",
    "                  f\"Train loss: {running_loss/print_every:.3f}.. \"\r\n",
    "                  f\"Test loss: {test_loss/len(test_data_loader):.3f}.. \"\r\n",
    "                  f\"Test accuracy: {accuracy/len(test_data_loader):.3f}\")\r\n",
    "            running_loss = 0\r\n",
    "            model.train()\r\n",
    "\r\n",
    "torch.save(model.state_dict(), 'model.pt')\r\n",
    "\r\n",
    "torch.save(model, 'model.pt')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\r\n",
    "import torch\r\n",
    "import torch.nn as nn\r\n",
    "from torchvision import datasets, transforms, models\r\n",
    "from numpy import isnan\r\n",
    "import torch.nn.functional as F\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "import sklearn\r\n",
    "from torch.nn import functional as F\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "import pandas as pd\r\n",
    "from datetime import datetime\r\n",
    "from os import path as os_path\r\n",
    "from torch.utils.data import DataLoader\r\n",
    "from sklearn import model_selection\r\n",
    "from sklearn import preprocessing\r\n",
    "from sklearn import preprocessing\r\n",
    "from sklearn.metrics import f1_score\r\n",
    "import torch.optim as optim\r\n",
    "#%%\r\n",
    "transforms_train = transforms.Compose([transforms.Resize(225),\r\n",
    "                                       transforms.CenterCrop(224),\r\n",
    "                                       transforms.ToTensor(),\r\n",
    "                                       transforms.Normalize([0.5, 0.5, 0.5],\r\n",
    "                                                            [0.5, 0.5, 0.5])])\r\n",
    "\r\n",
    "transforms_test = transforms.Compose([transforms.Resize(225),\r\n",
    "                                       transforms.CenterCrop(224),\r\n",
    "                                       transforms.ToTensor(),\r\n",
    "                                       transforms.Normalize([0.5, 0.5, 0.5],\r\n",
    "                                                            [0.5, 0.5, 0.5])])\r\n",
    "\r\n",
    "train_data = datasets.ImageFolder(root='data\\FIRE-SMOKE-DATASET\\Train', transform=transforms_train)\r\n",
    "test_data = datasets.ImageFolder(root='data\\FIRE-SMOKE-DATASET\\Test', transform=transforms_test)\r\n",
    "print(len(train_data), len(test_data))\r\n",
    "\r\n",
    "#%%\r\n",
    "#spliting the data\r\n",
    "train_data, val_data = torch.utils.data.random_split(train_data, [2400,300])\r\n",
    "#%%\r\n",
    "train_data_loader = torch.utils.data.DataLoader(train_data, batch_size=64, shuffle=True)\r\n",
    "val_data_loader = torch.utils.data.DataLoader(val_data, batch_size=64, shuffle=True)\r\n",
    "test_data_loader = torch.utils.data.DataLoader(test_data,  batch_size=64, shuffle=True)\r\n",
    "\r\n",
    "\r\n",
    "#%%\r\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() \r\n",
    "                                  else \"cpu\")\r\n",
    "model = models.resnet50(pretrained=True)\r\n",
    "print(model)\r\n",
    "#%%\r\n",
    "#How to Train an Image Classifier in PyTorch and use it to Perform Basic Inference on Single Images\r\n",
    "for param in model.parameters():\r\n",
    "    param.requires_grad = False\r\n",
    "    \r\n",
    "model.fc = nn.Sequential(nn.Linear(2048, 512),\r\n",
    "                                 nn.ReLU(),\r\n",
    "                                 nn.Dropout(0.2),\r\n",
    "                                 nn.Linear(512, 10),\r\n",
    "                                 nn.LogSoftmax(dim=1))\r\n",
    "criterion = nn.NLLLoss()\r\n",
    "optimizer = optim.Adam(model.fc.parameters(), lr=0.003)\r\n",
    "model.to(device)\r\n",
    "\r\n",
    "#%%\r\n",
    "epochs = 20\r\n",
    "steps = 0\r\n",
    "running_loss = 0\r\n",
    "print_every = 1\r\n",
    "train_losses, test_losses = [], []\r\n",
    "for epoch in range(epochs):\r\n",
    "    for inputs, labels in train_data_loader:\r\n",
    "        steps += 1\r\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\r\n",
    "        optimizer.zero_grad()\r\n",
    "        logps = model.forward(inputs)\r\n",
    "        loss = criterion(logps, labels)\r\n",
    "        loss.backward()\r\n",
    "        optimizer.step()\r\n",
    "        running_loss += loss.item()\r\n",
    "        \r\n",
    "        if steps % print_every == 0:\r\n",
    "            test_loss = 0\r\n",
    "            accuracy = 0\r\n",
    "            model.eval()\r\n",
    "            with torch.no_grad():\r\n",
    "                for inputs, labels in test_data_loader:\r\n",
    "                    inputs, labels = inputs.to(device),labels.to(device)\r\n",
    "                    logps = model.forward(inputs)\r\n",
    "                    batch_loss = criterion(logps, labels)\r\n",
    "                    test_loss += batch_loss.item()\r\n",
    "                    \r\n",
    "                    ps = torch.exp(logps)\r\n",
    "                    top_p, top_class = ps.topk(1, dim=1)\r\n",
    "                    equals = top_class == labels.view(*top_class.shape)\r\n",
    "                    accuracy +=torch.mean(equals.type(torch.FloatTensor)).item()\r\n",
    "            train_losses.append(running_loss/len(train_data_loader))\r\n",
    "            test_losses.append(test_loss/len(test_data_loader))                    \r\n",
    "            print(f\"Epoch {epoch+1}/{epochs}.. \"\r\n",
    "                  f\"Train loss: {running_loss/print_every:.3f}.. \"\r\n",
    "                  f\"Test loss: {test_loss/len(test_data_loader):.3f}.. \"\r\n",
    "                  f\"Test accuracy: {accuracy/len(test_data_loader):.3f}\")\r\n",
    "            running_loss = 0\r\n",
    "            model.train()\r\n",
    "\r\n",
    "torch.save(model.state_dict(), 'model.pt')\r\n",
    "\r\n",
    "torch.save(model, 'model.pt')"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}