{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "source": [
    "import torch\r\n",
    "import os\r\n",
    "import torchvision\r\n",
    "import numpy\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "from torchvision import datasets, transforms, models\r\n",
    "import resnet50\r\n",
    "from sklearn.metrics import f1_score\r\n",
    "Path_model = 'model_resnet/first_model_resnet.pt'"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "source": [
    "#import model resnet\r\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\r\n",
    "model = resnet50.Resnet_model()\r\n",
    "model = model.model\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "source": [
    "model = torch.load(Path_model,map_location=torch.device('cpu'))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "source": [
    "#model.load_state_dict(torch.load(Path_model, map_location=torch.device('cpu')))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "source": [
    "# using test dataset and leaving val for the end(should have been the opposite)\r\n",
    "transforms_train = transforms.Compose([transforms.Resize(225),\r\n",
    "                                       transforms.CenterCrop(224),\r\n",
    "                                       transforms.ToTensor(),\r\n",
    "                                       transforms.Normalize([0.5, 0.5, 0.5],\r\n",
    "                                                            [0.5, 0.5, 0.5])])\r\n",
    "\r\n",
    "transforms_test = transforms.Compose([transforms.Resize(225),\r\n",
    "                                       transforms.CenterCrop(224),\r\n",
    "                                       transforms.ToTensor(),\r\n",
    "                                       transforms.Normalize([0.5, 0.5, 0.5],\r\n",
    "                                                            [0.5, 0.5, 0.5])])\r\n",
    "\r\n",
    "train_data = datasets.ImageFolder(root='data\\FIRE-SMOKE-DATASET\\Train', transform=transforms_train)\r\n",
    "test_data = datasets.ImageFolder(root='data\\FIRE-SMOKE-DATASET\\Test', transform=transforms_test)\r\n",
    "print(len(train_data), len(test_data))\r\n",
    "\r\n",
    "#spliting the data\r\n",
    "train_data, val_data = torch.utils.data.random_split(train_data, [2400,300])\r\n",
    "\r\n",
    "train_data_loader = torch.utils.data.DataLoader(train_data, batch_size=64, shuffle=True)\r\n",
    "val_data_loader = torch.utils.data.DataLoader(val_data, batch_size=64, shuffle=True)\r\n",
    "test_data_loader = torch.utils.data.DataLoader(test_data,  batch_size=64, shuffle=True)\r\n",
    "\r\n",
    "classes =('Fire', 'Neutral', 'Smoke')\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2700 300\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "source": [
    "\r\n",
    "# calculating f1 score for the 5 models\r\n",
    "#Accuracy  and F1 score\r\n",
    "from sklearn.metrics import f1_score\r\n",
    "correct = 0\r\n",
    "total = 0\r\n",
    "with torch.no_grad():\r\n",
    "    for images, labels in val_data_loader:\r\n",
    "        output = model(images)\r\n",
    "        proba, predicted = torch.max(output, dim=1)\r\n",
    "        total += labels.size(0)\r\n",
    "        correct += (predicted == labels).sum().item()\r\n",
    "        f1_score_conv = f1_score(predicted.detach().numpy(), labels.detach().numpy(),average='micro')\r\n",
    "        '''\r\n",
    "        average:\r\n",
    "        This parameter is required for multiclass/multilabel targets.\r\n",
    "        If None, the scores for each class are returned. \r\n",
    "        Otherwise, this determines the type of averaging performed on the data\r\n",
    "        '''\r\n",
    "print (f'accuracy test set: {100 * correct/total}')\r\n",
    "print (f'F1 score test set: {f1_score_conv}')\r\n",
    "\r\n",
    "\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "accuracy test set: 92.66666666666667\n",
      "F1 score test set: 1.0\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# accuracy per each class\r\n",
    "correct = { a: 0 for a in classes}\r\n",
    "total =  { a: 0 for a in classes}\r\n",
    "\r\n",
    "with torch.no_grad():\r\n",
    "    for images, labels in test_data_loader:\r\n",
    "        output = model(images)\r\n",
    "        proba, predicted = torch.max(output, dim=1)\r\n",
    "        for label, prediction in zip(labels,predicted):\r\n",
    "            if label == prediction :\r\n",
    "                correct[classes[label]] +=1\r\n",
    "            total [classes[label]]+=1\r\n",
    "                \r\n",
    "        \r\n",
    "for c, k in correct.items():\r\n",
    "   print (f'accuracy test set class {c}: {100 * k/total[c]}')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# display an image from the test set\r\n",
    "dataiter = iter(test_data_loader)\r\n",
    "images, labels = dataiter.next()\r\n",
    "images = images[:4]\r\n",
    "labels = labels[:4]\r\n",
    "#print images\r\n",
    "\r\n",
    "def imshow(img):\r\n",
    "    img = img / 2 + 0.5 #unnormalize\r\n",
    "    npimg = img.numpy()\r\n",
    "    plt.imshow(numpy.transpose(npimg,(1,2,0)))\r\n",
    "    plt.show()\r\n",
    "imshow(torchvision.utils.make_grid(images))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#%%\r\n",
    "print('Truth:', ' '.join('%5s' % classes[labels[j]] for j in range(4)))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "dataiter = iter(train_data_loader)\r\n",
    "images, labels = dataiter.next()\r\n",
    "print(images.shape)\r\n",
    "classes[labels[0]]\r\n",
    "\r\n",
    "outputs = net(images)\r\n",
    "a , predicted = torch.max(outputs, 1)\r\n",
    "print('Predicted:', ' '.join('%5s' % classes[labels[j]] for j in range(4)))\r\n",
    "# %%\r\n",
    "labels.size()\r\n",
    "# %%"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def load_checkpoint(model, optimizer,filename='model_resnet/first_model_resnet.pt'):\r\n",
    "    # Note: Input model & optimizer should be pre-defined.  This routine only updates their states.\r\n",
    "    start_epoch = 0\r\n",
    "    if os.path.isfile(filename):\r\n",
    "        print(\"=> loading checkpoint '{}'\".format(filename))\r\n",
    "        checkpoint = torch.load(filename)\r\n",
    "        start_epoch = checkpoint['epoch']\r\n",
    "        model.load_state_dict(checkpoint['state_dict'])\r\n",
    "        optimizer.load_state_dict(checkpoint['optimizer'])\r\n",
    "        print(\"=> loaded checkpoint '{}' (epoch {})\"\r\n",
    "                  .format(filename, checkpoint['epoch']))\r\n",
    "    else:\r\n",
    "        print(\"=> no checkpoint found at '{}'\".format(filename))\r\n",
    "\r\n",
    "    return model, optimizer, start_epoch\r\n",
    "\r\n",
    "model, optimizer, start_epoch = load_checkpoint(model)\r\n",
    "\r\n",
    "                        \r\n",
    "import copy\r\n",
    "\r\n",
    "#model.load_state_dict(copy.deepcopy(torch.load('model_resnet/first_model_resnet.pt',device)))"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.1",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.1 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "6e877474a2f69abf93ff0788bb4753f9804efe5540cac16b9fab56086c1aa61b"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}